"""
This program works by reading in a .csv file (comma-separated values file)
that is generated by using a Praat script (http://www.fon.hum.uva.nl/praat/)
Here, the program can examine significant vocal features such as mean pitch,
jitter, and shimmer using several different classifiers. These classifiers can
then be used to assess qualities about a speaker's voice,  including whether or
not they have a specific accent.

Author: Emily Prud'hommeaux
Updated by: Jordan Edward Shea
"""
import numpy as np
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2
from sklearn.model_selection import cross_val_score
import sys

f = open(sys.argv[1])

# read in the first line as the feature labels
# so you can know what you're removing or adding
labels = f.readline().rstrip().split(",")

## read features into list of lists (data)
## read diagnosis into a list of lists (target)
target = []
data = []
print("The features are:", labels)
for line in f:
    parts = line.split(",")
    data.append([float(p) for p in parts[0:-1]])
    target.append(float(parts[-1]))

## conver to numpy arrays
nptarget = np.array(target)
npdata = np.array(data)

## see how many features and training examples you have
print("You have ", npdata.shape[0], "training instanaces")
print("You have ", npdata.shape[1], "features")

## very, very basic classification with Naive Bayes classifier
gnb = GaussianNB()
gnb_scores = cross_val_score(gnb, npdata, nptarget, cv=5, scoring='f1')
print("GNB classification F1:", np.average(gnb_scores))

## Decision Tree Classifier
dtc = DecisionTreeClassifier()
dtc_scores = cross_val_score(dtc, npdata, nptarget, cv=5, scoring='f1')
print("DTC classification F1:", np.average(dtc_scores))


## Random Forest Classifier
rfc = RandomForestClassifier()
rfc_scores = cross_val_score(rfc, npdata, nptarget, cv=5, scoring='f1')
print("RFC classification F1:", np.average(rfc_scores))

## Support Vector Classifier
svc = SVC()
svc_scores = cross_val_score(svc, npdata, nptarget, cv=5, scoring='f1')
print("SVC classification F1:", np.average(svc_scores))

## Feature Selection from SVC
print("Using LinearSVC-Model Fitting to Select Best Features")
svc_fit = LinearSVC().fit(npdata, nptarget)
svc_model = SelectFromModel(svc_fit, prefit=True)
npdata_new = svc_model.transform(npdata)
svc_fit_scores = cross_val_score(svc, npdata_new, nptarget, cv=5, scoring='f1')
print("SVC Classification Scores on LinearSVC fit model: ", np.average(svc_fit_scores))

#Feature-Selection using K-Best
print("Performing 3-best feature selection using the chi2 test")
skb = SelectKBest(chi2, k=3).fit(npdata, nptarget)
best_features = skb.get_support(indices=True)
best_feature_labels = [labels[x] for x in best_features]
print("Best features from 3-Best Selection: " + ', '.join(best_feature_labels))

npdata_knew = skb.transform(npdata)
print(npdata_knew.shape)
print()

## very, very basic classification with Naive Bayes classifier
gnb = GaussianNB()
gnb_scores = cross_val_score(gnb, npdata_knew, nptarget, cv=5, scoring='f1')
print("GNB classification F1 3-Best:", np.average(gnb_scores))

## Decision Tree Classifier
dtc = DecisionTreeClassifier()
dtc_scores = cross_val_score(dtc, npdata_knew, nptarget, cv=5, scoring='f1')
print("DTC classification F1 3-Best:", np.average(dtc_scores))


## Random Forest Classifier
rfc = RandomForestClassifier()
rfc_scores = cross_val_score(rfc, npdata_knew, nptarget, cv=5, scoring='f1')
print("RFC classification F1 3-Best:", np.average(rfc_scores))

## Support Vector Classifier
svc = SVC()
svc_scores = cross_val_score(svc, npdata_knew, nptarget, cv=5, scoring='f1')
print("SVC Scores")
print(svc_scores)
print("SVC classification F1 3-Best:", np.average(svc_scores))




## Let's say you only want to use features 3 and 4...
#npdata = npdata[:,1:3]
#scores = cross_val_score(gnb, npdata, nptarget, cv=5, scoring='f1')
#print("Baseline classification F1:", np.average(scores))

